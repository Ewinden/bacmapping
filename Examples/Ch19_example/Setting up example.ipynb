{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bacmapping as bacm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from Bio import Entrez\n",
    "from Bio import SeqIO\n",
    "from ftplib import FTP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = os.getcwd()\n",
    "#print(wd)\n",
    "acc = 'NC_000019.10'\n",
    "lib = 'RP11'\n",
    "chrom = '19'\n",
    "fcnames = ['seqid','source','type','start','end','score','strand','phase','attributes']\n",
    "email = 'ewinden@wisc.edu'\n",
    "chunk_size = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SeqIO.index_db('/media/data1/ewinden/HG38/bacmapping/Examples/Ch19_example/sequences/seqindex.sqlite', filenames=['/media/data1/ewinden/HG38/bacmapping/Examples/Ch19_example/sequences/allsequences.fasta'], format='fasta', key_function=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onlyType = True\n",
    "vtype = 'BAC'\n",
    "\n",
    "#Set taxid and version (most recent human)\n",
    "version = '118'\n",
    "taxid = '9606'\n",
    "species = 'Homo_sapiens'\n",
    "\n",
    "#Setup names\n",
    "cloneacstate = 'clone_acstate_'+taxid+'.out'\n",
    "librarys = 'library_'+taxid+'.out'\n",
    "ucname = version + '.unique_'\n",
    "\n",
    "#Setup folders\n",
    "cwd = os.getcwd()\n",
    "clonesDetails = os.path.join(cwd,'details')\n",
    "clonesSequences = os.path.join(cwd,'sequences')\n",
    "clonesDetailsRepaired = os.path.join(clonesDetails,'repaired')\n",
    "clonesDetailsReordered = os.path.join(clonesDetails,'reordered')\n",
    "clonesDetailsInfo = os.path.join(clonesDetails,'info')\n",
    "\n",
    "for f in [clonesDetails, clonesSequences, clonesDetailsRepaired,clonesDetailsReordered, clonesDetailsInfo]:\n",
    "    os.makedirs(f, exist_ok=True)\n",
    "\n",
    "ucstpaths = []\n",
    "ucstlibs = []\n",
    "\n",
    "#Login to NCBI FTP to download details files\n",
    "libraryDetails = os.path.join(clonesDetails,librarys)\n",
    "cloneacstatepath = os.path.join(clonesDetails,cloneacstate)\n",
    "with FTP(\"ftp.ncbi.nih.gov\") as ftp:\n",
    "    ftp.login()\n",
    "    ftp.cwd('repository/clone/reports/'+species+'/')\n",
    "    for f, p in [[librarys,libraryDetails],[cloneacstate, cloneacstatepath]]:\n",
    "        if os.path.exists(p) == False:\n",
    "            ftp.retrbinary(\"RETR \" + f ,open(p, 'wb').write)\n",
    "    filenames = ftp.nlst()\n",
    "    ucst = [x for x in filenames if ucname in x]\n",
    "\n",
    "    #Narrow down\n",
    "    if onlyType==True:\n",
    "        librariesToInclude = os.path.join(clonesDetails, 'includedLibraries.csv')\n",
    "        fullp = pd.read_csv(libraryDetails, sep='\\t')\n",
    "        cut = fullp[fullp['vtype'] == vtype]\n",
    "        dcut = cut[cut['libabbr'] == lib]\n",
    "        uselibs = dcut['libabbr']\n",
    "        uselibs.to_csv(librariesToInclude, index = False, header = False)\n",
    "        ucst = [x for x in ucst if x[:x.find('.')] in set(uselibs)]\n",
    "\n",
    "    ucstlibs = ucst\n",
    "\n",
    "    for f in ucst:\n",
    "        p = os.path.join(clonesDetails,f)\n",
    "        ucstpaths.append(p)\n",
    "        if os.path.exists(p) == False:\n",
    "            ftp.retrbinary(\"RETR \" + f ,open(p, 'wb').write)\n",
    "\n",
    "#Get accession list\n",
    "ucstpaths= [os.path.join(clonesDetails,x) for x in ucst]\n",
    "ucstlibs = list(set([uc[:uc.find('.')] for uc in ucst if ('unique' in uc)]))\n",
    "\n",
    "#Split unique files into a header and details, save fixed files and by accession\n",
    "nucpaths = []\n",
    "fcnames= ['seqid','source','type','start','end','score','strand','phase','attributes']\n",
    "for lib in ucstlibs:\n",
    "    ucs = [x for x in ucstpaths if lib+'.' in x]\n",
    "    ucu = ucs[0][:ucs[0].find('unique')]+'unique.gff'\n",
    "    with open(ucu, 'w') as ci:\n",
    "        ci.write('\\t'.join(fcnames))\n",
    "    ucurepaired = os.path.join(clonesDetailsRepaired,lib+'_repaired.gff')\n",
    "    nucpaths.append(ucu)\n",
    "    for uc in ucs:\n",
    "        ucinfo = os.path.join(clonesDetailsInfo, uc[uc.find(lib):] + '.info.txt')\n",
    "        stahp = False\n",
    "        for header in pd.read_csv(uc, sep='\\t', header=None, chunksize=7):\n",
    "            header.to_csv(ucinfo)\n",
    "            break\n",
    "        for tlines in pd.read_csv(uc, sep='\\t', skiprows=7, chunksize=1, names = fcnames):\n",
    "            if tlines.empty:\n",
    "                stahp = True\n",
    "                break\n",
    "            atts = tlines['attributes'].item().split(';')\n",
    "            cnames = [x[:x.find('=')] for x in atts]\n",
    "            middles = [x.find('=') for x in atts]\n",
    "        if stahp == True:\n",
    "            continue\n",
    "        for tlines in pd.read_csv(uc, sep='\\t', skiprows=7, chunksize=chunk_size, names = fcnames):\n",
    "            tlines = tlines[tlines['seqid'] == acc]\n",
    "            tlines.to_csv(ucu, mode='a', index=False, header=False, sep='\\t')\n",
    "            newcols = tlines['attributes'].apply(bacm.splitAttributesWithMids, middles=middles)\n",
    "            newcols.columns = cnames\n",
    "            tlinesrep = pd.concat([tlines,newcols], axis=1)\n",
    "            tlinesrep['Library'] = lib\n",
    "            tlinesrep.to_csv(ucurepaired, mode='a', index=False, header=False, sep='\\t')\n",
    "            accessions = tlinesrep['seqid'].unique()\n",
    "            for acc in accessions:\n",
    "                tlinesacc = tlinesrep[tlinesrep['seqid'] == acc]\n",
    "                ucureorder = os.path.join(clonesDetailsReordered,acc)\n",
    "                if os.path.exists(ucureorder) == False:\n",
    "                    tlinesacc.to_csv(ucureorder, mode='w', index = False, header = True, sep = '\\t')\n",
    "                else:\n",
    "                    tlinesacc.to_csv(ucureorder, mode='a', index = False, header = False, sep = '\\t')\n",
    "\n",
    "for fpath in ucstpaths:\n",
    "    inputf = pd.read_csv(fpath, sep='\\t', skiprows=8, names = fcnames)\n",
    "    outputf = inputf[inputf['seqid'] == acc]\n",
    "    outputf.to_csv(fpath, sep='\\t')\n",
    "\n",
    "#Get accessions of sequenced clones from clone_acstate\n",
    "seqdclones = pd.read_csv(cloneacstatepath, sep='\\t')\n",
    "finseqclones = seqdclones[(seqdclones['Stdn']=='Y') & (seqdclones['CloneState']=='fin') & (seqdclones['Chrom']==chrom) & (seqdclones['LibAbbr']==lib)]\n",
    "finseqaccs = finseqclones['Accession'].unique()\n",
    "finseqclones.to_csv(os.path.join(clonesDetails,'clone_acstate_'+taxid+'_onlyfinished.out'),sep='\\t',index=False)\n",
    "\n",
    "#Get accessions for placed clones\n",
    "allplacedaccs = []\n",
    "for uc in nucpaths:\n",
    "    uccur = pd.read_csv(uc, sep='\\t')\n",
    "    plasecaccs = uccur['seqid'].unique()\n",
    "    [allplacedaccs.append(x) for x in list(plasecaccs) if x not in allplacedaccs]\n",
    "    \n",
    "#Make superfile and save accessions lists\n",
    "allaccs = allplacedaccs + list(finseqaccs)\n",
    "with open(os.path.join(clonesSequences,'Accessions.csv'), 'w') as accessions:\n",
    "    accessions.writelines('\\n'.join(allaccs) + '\\n')\n",
    "with open(os.path.join(clonesSequences,'PlacedAccessions.csv'), 'w') as accessions:\n",
    "    accessions.writelines('\\n'.join(allplacedaccs) + '\\n')\n",
    "with open(os.path.join(clonesSequences,'SequencedAccessions.csv'), 'w') as accessions:\n",
    "    accessions.writelines('\\n'.join(finseqaccs) + '\\n')\n",
    "\n",
    "\n",
    "#Download all sequences\n",
    "Entrez.email = email  # Always tell NCBI who you are\n",
    "save = os.path.join(clonesSequences,'allsequences.fasta')\n",
    "net_handle = Entrez.efetch(db=\"nucleotide\", id=allaccs, rettype=\"fasta\", retmode=\"text\")\n",
    "out_handle = open(save, \"w\")\n",
    "out_handle.write(net_handle.read())\n",
    "out_handle.close()\n",
    "net_handle.close()\n",
    "\n",
    "seqind = os.path.join(clonesSequences, 'seqindex.sqlite')\n",
    "SeqIO.index_db(seqind, save, 'fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bacm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
